# Potential Harms of Large Language Models

<br>

## 1. Loss of Human Creativity

- Humans are known for their imagination and creative thinking.
- If we start using AI for every creative task (writing, drawing, etc.), people might stop using their own creative skills.
- Over time, we may lose our natural ability to think creatively.

<br>

## 2. Too Much Dependence on AI

- People may start using AI for everything — writing, thinking, even basic decisions.
- This could lead to less real-life interaction and more isolation.
- For example, instead of going outside to enjoy nature, someone might just ask AI to describe it.
- This reduces the joy of real-world experiences.

<br>

## 3. Problems with Copyright and Trust

- AI can copy styles of artists, writers, and speakers — which can raise copyright issues.
- It can also create fake or harmful content that sounds very real.
- This makes it hard to know if something was written by a human or AI.
- Fake content might not get caught in time and could cause harm.

<br>

## 3. Psychological Impact

- People may start fully trusting everything AI says, even if it's wrong.
- LLMs can sometimes create false or misleading content that *sounds* very convincing.
- Over time, users might adopt extreme or biased views just because AI keeps presenting them that way.
- As trust in AI grows, people might forget it’s just a tool — not a human or expert.
- Talking to AI too much instead of real people can make us feel distant, frustrated, or even stop trusting others.

<br>

