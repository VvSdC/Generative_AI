# Potential Harms of Large Language Models

## Table of Contents
- [1. Loss of Human Creativity](#1-loss-of-human-creativity)
- [2. Too Much Dependence on AI](#2-too-much-dependence-on-ai)
- [3. Problems with Copyright and Trust](#3-problems-with-copyright-and-trust)
- [4. Psychological Impact](#4-psychological-impact)
- [5. Data Privacy](#5-data-privacy)
- [6. Replacing Humans in Jobs](#6-replacing-humans-in-jobs)
- [7. Vulnerability Due to Prompt Hacking](#7-vulnerability-due-to-prompt-hacking)

<br>

## 1. Loss of Human Creativity

- Humans are known for their imagination and creative thinking.
- If we start using AI for every creative task (writing, drawing, etc.), people might stop using their own creative skills.
- Over time, we may lose our natural ability to think creatively.

<br>

## 2. Too Much Dependence on AI

- People may start using AI for everything — writing, thinking, even basic decisions.
- This could lead to less real-life interaction and more isolation.
- For example, instead of going outside to enjoy nature, someone might just ask AI to describe it.
- This reduces the joy of real-world experiences.

<br>

## 3. Problems with Copyright and Trust

- AI can copy styles of artists, writers, and speakers — which can raise copyright issues.
- It can also create fake or harmful content that sounds very real.
- This makes it hard to know if something was written by a human or AI.
- Fake content might not get caught in time and could cause harm.

<br>

## 4. Psychological Impact

- People may start fully trusting everything AI says, even if it's wrong.
- LLMs can sometimes create false or misleading content that *sounds* very convincing.
- Over time, users might adopt extreme or biased views just because AI keeps presenting them that way.
- As trust in AI grows, people might forget it’s just a tool — not a human or expert.
- Talking to AI too much instead of real people can make us feel distant, frustrated, or even stop trusting others.

<br>

## 5. Data Privacy

- LLMs are trained on large datasets, which might include personal or sensitive user information (PII).
- This information should be removed before training, but that doesn't always happen.
- Some models also store user inputs (questions and responses) for a short time.
- If this data is kept too long, used to improve the model, or leaked in a data breach, it can lead to serious privacy issues.

<br>

## 6. Replacing Humans in Jobs

- AI can now create content, give advice, and help make decisions — things that many jobs require.
- This raises concerns that AI could take over many human jobs.
- Goldman Sachs estimated that around 300 million jobs could be lost or changed because of AI.
- AI is fast and accurate, and can work across many different fields.
- With advanced tools and LLM-powered agents, AI is getting even more capable.
- In the future, people may need to become skilled at guiding AI and double-checking its outputs, rather than doing the tasks themselves.

<br>

## 7. Vulnerability Due to Prompt Hacking

- Prompt hacking can trick AI systems into revealing hidden prompts or internal system details.
- Attackers may use prompt injection to break how an AI application works.
- Jailbreak techniques can force models to generate content that goes against safety rules.
- People around the world often try to find ways to bypass these restrictions.
- As they experiment, new weaknesses — and even unexpected behaviors — of LLMs are being discovered.

<br>
